---
title: Latest 10 Trending Repositories - March 22, 2025
labels: documentation
---
# ğŸ“š Weekly Trending Repositories Update

### ğŸ“… Date: March 22, 2025

Welcome to today's collection of the latest research papers! Below you'll find the top 10 papers for each category.

ğŸ’¡ **Note**: For a better reading experience and access to more papers, please visit our [Github Repository](https://github.com/marc-ko/daily-trending-repo).

---

| **Title** | **Description** | **Language** | **Summary** | **Tags** | **Stars Count** | **HTML URL** |
| --- | --- | --- | --- | --- | --- | --- |
| **[rust-stakeholder](https://github.com/giacomo-b/rust-stakeholder)** | Generate impressive-looking terminal output to look busy when stakeholders walk by | Rust | # rust-stakeholder

![Career Status](https://img.shields.io/badge/career-saved-success) ![Stakeholders](https://img.shields.io/badge/stakeholders-impressed-yellow)

**SATIRE ALERT**: This is a joke project poking fun at impostor syndrome and workplace dynamics in tech. No actual deception recommended!

<p align="center">
  <img src="./assets/demo.gif" alt="animated" />
</p>

## Become an irreplaceable 10x developer in 30 seconds flat

Why learn actual skills when you can just *look* impressive instead?

Introducing **rust-stakeholder** - a CLI tool that generates absolutely meaningless but impressive-looking terminal output to convince everyone you're a coding genius without writing a single line of useful code.

> "After using rust-stakeholder, I'm no longer asked about my deadlines but rather for my insights during board meetings." - Developer who still hasn't completed their tickets from last sprint

Remember, it's not about your actual contribution to the codebase; it's about how complicated your terminal looks when the VP of Engineering walks by. Nothing says "I'm vital to this company" like 15 progress bars, cryptic error messages you seem unfazed by, and technical jargon nobody understands.

## Features that add zero value but look incredibly important

- ğŸ–¥ï¸ **Dazzling development simulations**: Make it look like you're solving CERN-level computing problems when you're actually just refreshing Reddit.
- ğŸ§  **Meaningless jargon generator**: Impress with phrases like "Implemented non-euclidean topology optimization for multi-dimensional data representation" (no, it doesn't mean anything).
- ğŸ“Š **Convincing progress bars**: Nothing says "I'm working" like a progress bar slowly advancing while you're in the break room.
- ğŸŒ **Fake network activity**: Simulate mission-critical API requests that are actually just your computer talking to itself.
- ğŸš¨ **Artificial crisis mode**: Generate realistic-looking alerts so people think you're heroically averting disasters.
- ğŸ‘¥ **Imaginary team activity**: Pretend your invisible friends are sending you important pull requests.
- ğŸ® **Domain chameleon**: Switch between backend, frontend, blockchain, and 7 other domains faster than you can say "full-stack developer."

## Installation

```bash
cargo install --git https://github.com/giacomo-b/rust-stakeholder.git
```

Or build from source (warning: might involve actual programming):

```bash
git clone https://github.com/giacomo-b/rust-stakeholder.git
cd rust-stakeholder
cargo build --release # Look at you doing real developer things!
```

## Docker

Build image:

```bash
docker build -t rust-stakeholder .
```

Usage:

Basic usage:

```bash
docker run -t --rm rust-stakeholder
```

All commands below can be used through:

```bash
docker run -t --rm rust-stakeholder [arguments]
```

## Usage for career advancement

Basic usage (for entry-level imposters):

```bash
rust-stakeholder
```

Advanced usage (for senior imposters):

```bash
# Impress the blockchain VC investors
rust-stakeholder --dev-type blockchain --jargon extreme --alerts

# Look busy during performance review season
rust-stakeholder --complexity extreme --team --duration 1800

# Convince everyone you're a 10x game developer
rust-stakeholder --dev-type game-development --framework "Custom Engine" --jargon high

# For the data science frauds
rust-stakeholder --dev-type data-science --jargon extreme --project "Neural-Quantum-Blockchain-AI"

# Emergency mode: Your project is due tomorrow and you haven't started
rust-stakeholder --dev-type fullstack --complexity extreme --alerts --team
```

## Benefits

- **Promotion fast-track**: Skip the tedious "delivering value" step entirely.
- **Meeting domination**: Let it run in the background during calls to seem busy.
- **Deadline extensions**: "Sorry, still resolving those critical system alerts."
- **Salary negotiation**: Just leave it running during your review.
- **Job security**: Become the only person who seems to understand your fictional systems.

## Testimonials

> "I left rust-stakeholder running over the weekend. When I came back on Monday, I had been promoted to Principal Engineer." - Anonymous

> "No one knows what I do, and thanks to rust-stakeholder, neither do I." - Satisfied User

> "Since installing rust-stakeholder, my colleagues have stopped asking me for help because my work 'looks too advanced'." - Senior Imposter Engineer

## Tests? What tests?

Currently, this package has the same amount of test coverage as your excuses for missing deadlines - absolutely none.

Much like your actual development skills while using this tool, tests are purely theoretical at this point. But | <details><summary>blazi...</summary><p>blazingly-fast, meme, rust</p></details> | 1811 | https://github.com/giacomo-b/rust-stakeholder |
| **[Second-Me](https://github.com/mindverse/Second-Me)** | Train your AI self, amplify you, bridge the world | Python | # Second Me: Your AI Self

![Second Me](https://github.com/mindverse/Second-Me/blob/master/images/cover.png)

<div align="center">
  
[![Homepage](https://img.shields.io/badge/Second_Me-Homepage-blue?style=flat-square&logo=homebridge)](https://www.secondme.io/)
[![Report](https://img.shields.io/badge/Paper-arXiv-red?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2503.08102)
[![Discord](https://img.shields.io/badge/Chat-Discord-5865F2?style=flat-square&logo=discord&logoColor=white)](https://discord.gg/GpWHQNUwrg)
[![Twitter](https://img.shields.io/badge/Follow-@SecondMe_AI-1DA1F2?style=flat-square&logo=x&logoColor=white)](https://x.com/SecondMe_AI1)
[![Reddit](https://img.shields.io/badge/Join-Reddit-FF4500?style=flat-square&logo=reddit&logoColor=white)](https://www.reddit.com/r/SecondMeAI/)

</div>

## Our Vision

At Second Me, we believe in creating an AI that enhances individuality rather than diminishing it. Our goal is to empower users to craft their own AI selvesâ€”an open-source prototype that preserves personal identity, delivers context, and protects interests. 

With **Second Me**, your AI is locally trained and hosted, ensuring you maintain control over your data while being globally connected. This platform serves as your digital identity interface, fostering collaboration among AI selves and enabling the development of innovative AI applications.

## Key Features

### **Train Your AI Self** with AI-Native Memory
Start training your Second Me today with your own memories! Our Hierarchical Memory Modeling (HMM) and Me-Alignment Algorithm allow your AI to capture your identity, understand context, and reflect you authentically.

<p align="center">
  <img src="https://github.com/user-attachments/assets/a84c6135-26dc-4413-82aa-f4a373c0ff89" width="94%" />
</p>

### **Scale Your Intelligence** on the Second Me Network
Launch your AI self from your laptop onto our decentralized network, allowing others and applications to connect with your permission, sharing your context as your digital identity.

<p align="center">
  <img src="https://github.com/user-attachments/assets/9a74a3f4-d8fd-41c1-8f24-534ed94c842a" width="94%" />
</p>

### Build Tomorrowâ€™s Apps with Second Me
- **Roleplay**: Switch personas for different scenarios.
- **AI Space**: Collaborate with other Second Mes to generate ideas or solve problems.

<p align="center">
  <img src="https://github.com/user-attachments/assets/bc6125c1-c84f-4ecc-b620-8932cc408094" width="94%" />
</p>

### 100% **Privacy and Control**
Your information and intelligence remain local and completely private, unlike traditional centralized AI systems.

## Getting Started

### Prerequisites
- macOS operating system
- Git installed
- Homebrew (recommended for system dependencies)
- Xcode Command Line Tools

#### Installing Xcode Command Line Tools
To install Xcode Command Line Tools, run:
```bash
xcode-select --install
```
Then, accept the license agreement:
```bash
sudo xcodebuild -license accept
```

### Installation and Setup

1. Clone the repository:
```bash
git clone git@github.com:Mindverse/Second-Me.git
cd Second-Me
```

2. Set up the environment:
Using make:
```bash
make setup
```
Or use the setup script directly:
```bash
./scripts/setup.sh
```

3. Start the service:
Using make:
```bash
make start
```
Or use the script directly:
```bash
./scripts/start.sh
```

4. Access the service:
Open your browser and visit `http://localhost:3000`.

5. For help and more commands:
Using make:
```bash
make help
```

## Tutorial
Follow the [User  tutorial](https://second-me.gitbook.io/a-new-ai-species-making-we-matter-again) to build your Second Me.

## Coming Soon ğŸš€

### ğŸ”¬ Model Enhancement Features
- **Long Chain-of-Thought Training Pipeline**
- **Direct Preference Optimization for L2 Model**
- **Data Filtering for Training**
- **Apple Silicon Support**

### ğŸ› ï¸ Product Features
- **Natural Language Memory Summarization**

## Contributing

We welcome contributions! Check out our [Contribution Guide](./CONTR |  | 1481 | https://github.com/mindverse/Second-Me |
| **[cursor-talk-to-figma-mcp](https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp)** | Cursor Talk To Figma MCP | TypeScript | # Cursor Talk to Figma MCP

This project implements a Model Context Protocol (MCP) integration between Cursor AI and Figma, allowing Cursor to communicate with Figma for reading designs and modifying them programmatically.

## Project Structure

- **`src/talk_to_figma_mcp/`**: TypeScript MCP server for Figma integration.
- **`src/cursor_mcp_plugin/`**: Figma plugin for communicating with Cursor.
- **`src/socket.ts`**: WebSocket server that facilitates communication between the MCP server and Figma plugin.

## Get Started

1. **Install Bun** if you haven't already:

   ```bash
   curl -fsSL https://bun.sh/install | bash
   ```

2. **Run setup**; this will also install MCP in your Cursor's active project:

   ```bash
   bun setup
   ```

3. **Start the WebSocket server**:

   ```bash
   bun start
   ```

4. **Install the Figma Plugin**.

## Quick Video Tutorial

[![image](images/tutorial.jpg)](https://www.linkedin.com/posts/sonnylazuardi_just-wanted-to-share-my-latest-experiment-activity-7307821553654657024-yrh8)

## Manual Setup and Installation

### MCP Server: Integration with Cursor

Add the server to your Cursor MCP configuration in `~/.cursor/mcp.json`:

```json
{
  "mcpServers": {
    "TalkToFigma": {
      "command": "bun",
      "args": [
        "/path/to/cursor-talk-to-figma-mcp/src/talk_to_figma_mcp/server.ts"
      ]
    }
  }
}
```

### WebSocket Server

Start the WebSocket server:

```bash
bun run src/socket.ts
```

### Figma Plugin

1. In Figma, go to **Plugins > Development > New Plugin**.
2. Choose **"Link existing plugin"**.
3. Select the `src/cursor_mcp_plugin/manifest.json` file.
4. The plugin should now be available in your Figma development plugins.

## Usage

1. Start the WebSocket server.
2. Install the MCP server in Cursor.
3. Open Figma and run the Cursor MCP Plugin.
4. Connect the plugin to the WebSocket server by joining a channel using `join_channel`.
5. Use Cursor to communicate with Figma using the MCP tools.

## MCP Tools

The MCP server provides the following tools for interacting with Figma:

### Document & Selection

- **`get_document_info`**: Get information about the current Figma document.
- **`get_selection`**: Get information about the current selection.
- **`get_node_info`**: Get detailed information about a specific node.

### Creating Elements

- **`create_rectangle`**: Create a new rectangle with position, size, and optional name.
- **`create_frame`**: Create a new frame with position, size, and optional name.
- **`create_text`**: Create a new text node with customizable font properties.

### Modifying Text Content

- **`set_text_content`**: Set the text content of an existing text node.

### Styling

- **`set_fill_color`**: Set the fill color of a node (RGBA).
- **`set_stroke_color`**: Set the stroke color and weight of a node.
- **`set_corner_radius`**: Set the corner radius of a node with optional per-corner control.

### Layout & Organization

- **`move_node`**: Move a node to a new position.
- **`resize_node`**: Resize a node with new dimensions.
- **`delete_node`**: Delete a node.

### Components & Styles

- **`get_styles`**: Get information about local styles.
- **`get_local_components`**: Get information about local components.
- **`get_team_components`**: Get information about team components.
- **`create_component_instance`**: Create an instance of a component.

### Export & Advanced

- **`export_node_as_image`**: Export a node as an image (PNG, JPG, SVG, or PDF).
- **`execute_figma_code`**: Execute arbitrary JavaScript code in Figma (use with caution).

### Connection Management

- **`join_channel`**: Join a specific channel to communicate with Figma.

## Development

### Building the Figma Plugin

1. Navigate to the Figma plugin directory:

   ```bash
   cd src/cursor_mcp_plugin
   ```

2. Edit `code.js` and `ui.html`.

## Best Practices

When working with the Figma MCP:

1. Always join a channel before sending commands.
2. Get document overview using `get_document_info` first.
3. Check current selection with `get_selection` before modifications.
4 | <details><summary>agent...</summary><p>agent, agentic, agentic-ai, ai, cursor, design, figma, mcp</p></details> | 1257 | https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp |
| **[anubis](https://github.com/TecharoHQ/anubis)** | Weighs the soul of incoming HTTP requests using proof-of-work to stop AI crawlers | Go | # Anubis

<center>
<img width=256 src="./cmd/anubis/static/img/happy.webp" alt="A smiling chibi dark-skinned anthro jackal with brown hair and tall ears looking victorious with a thumbs-up" />
</center>

![enbyware](https://pride-badges.pony.workers.dev/static/v1?label=enbyware&labelColor=%23555&stripeWidth=8&stripeColors=FCF434%2CFFFFFF%2C9C59D1%2C2C2C2C)
![GitHub Issues or Pull Requests by label](https://img.shields.io/github/issues/TecharoHQ/anubis)
![GitHub go.mod Go version](https://img.shields.io/github/go-mod/go-version/TecharoHQ/anubis)
![language count](https://img.shields.io/github/languages/count/TecharoHQ/anubis)
![repo size](https://img.shields.io/github/repo-size/TecharoHQ/anubis)

Anubis [weighs the soul of your connection](https://en.wikipedia.org/wiki/Weighing_of_souls) using a SHA-256 proof-of-work challenge to protect upstream resources from scraper bots.

## Overview

Installing and using Anubis will likely prevent your website from being indexed by some search engines. This is considered a feature, not a bug. The aggressive behavior of AI scraper bots has necessitated this approach. While Cloudflare is often sufficient for protection, Anubis is an alternative for those who cannot or do not wish to use it.

If you want to try this out, connect to [anubis.techaro.lol](https://anubis.techaro.lol).

## Support

If you encounter any issues while running Anubis, please [open an issue](https://github.com/TecharoHQ/anubis/issues/new?template=Blank+issue) and tag it with the Anubis tag. Be sure to include all relevant information for diagnosis.

For live chat support, consider joining the [Patreon](https://patreon.com/cadey) and asking in the Patron Discord in the `#anubis` channel.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=TecharoHQ/anubis&type=Date)](https://www.star-history.com/#TecharoHQ/anubis&Date) | <details><summary>defen...</summary><p>defense, security</p></details> | 885 | https://github.com/TecharoHQ/anubis |
| **[unity-mcp](https://github.com/justinpbarnett/unity-mcp)** | A Unity MCP server that allows MCP clients like Claude Desktop or Cursor to perform Unity Editor actions. | C# | # Unity MCP Package

The Unity MCP Package is an innovative tool designed to facilitate seamless communication between Unity and Large Language Models (LLMs) such as Claude Desktop through the **Model Context Protocol (MCP)**. This package acts as a bridge, enabling developers to send commands to and receive responses from MCP-compliant tools, thereby automating workflows, manipulating assets, and controlling the Unity Editor programmatically.

Welcome to the initial release of this open-source project! Whether you are looking to integrate LLMs into your Unity workflow or contribute to an exciting new tool, I appreciate you taking the time to check out this project.

## Overview

The Unity MCP Server provides a bidirectional communication channel between Unity (via C#) and a Python server, enabling:

- **Asset Management**: Create, import, and manipulate Unity assets programmatically.
- **Scene Control**: Manage scenes, objects, and their properties.
- **Material Editing**: Modify materials and their properties.
- **Script Integration**: View, create, and update Unity scripts.
- **Editor Automation**: Control Unity Editor functions like undo, redo, play, and build.

This project is perfect for developers who want to leverage LLMs to enhance their Unity projects or automate repetitive tasks.

## Installation

### Prerequisites

- Unity 2020.3 LTS or newer (âš ï¸ only works in URP projects currently)
- Python 3.7 or newer
- uv package manager

**If you're on Mac, please install uv as follows:**

```bash
brew install uv
```

**On Windows:**

```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

Then, add to your PATH:

```bash
set Path=%USERPROFILE%\.local\bin;%Path%
```

**On Linux:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

For further installation instructions, visit the [Install uv](https://docs.astral.sh/uv/getting-started/installation/) website.

**âš ï¸ Do not proceed before installing UV**

### Unity Package Installation

1. **Add the Unity Package**

   - Open Unity Package Manager (`Window > Package Manager`)
   - Click the `+` button and select `Add package from git URL`
   - Enter: `https://github.com/justinpbarnett/unity-mcp.git`

2. **Set Up Python Environment**
   - Navigate to the Python directory in your project:
     - If installed as a package: `Library/PackageCache/com.justinpbarnett.unity-mcp/Python`
     - If installed locally: `Assets/unity-mcp/Python`
   - Install dependencies:
     ```bash
     uv venv
     uv pip install -e .
     ```

### MCP Client Integration

1. Open the Unity MCP window (`Window > Unity MCP`)
2. Click the "Auto Configure" button for your desired MCP client.
3. The status indicator should show green with a "Configured" message.

Alternatively, manually configure your MCP client:

1. Open the Unity MCP window (`Window > Unity MCP`)
2. Click the "Manually Configure" button for your desired MCP client.
3. Copy the JSON code below to the config file.

```json
{
  "mcpServers": {
    "unityMCP": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/your/unity-mcp/Python",
        "run",
        "server.py"
      ]
    }
  }
}
```

Replace `/path/to/your/unity-mcp/Python` with the actual path to the Unity MCP Python directory.

**âš ï¸ Only run one instance of the MCP server (either on Cursor or Claude Desktop), not both.**

4. **Start Claude Desktop or Cursor**
   - Launch your preferred tool.
   - The Unity MCP Server will automatically start and connect.

## Usage

Once configured, you can use the MCP Client to interact with Unity directly through their chat interface.

## Features

- **Bidirectional Communication**: Seamlessly send and receive data between Unity and LLMs.
- **Asset Management**: Import assets, instantiate prefabs, and create new prefabs programmatically.
- **Scene Control**: Open, save, and modify scenes, plus create and manipulate game objects.
- **Material Editing**: Apply and modify materials with ease.
- **Script Integration**: Create, view, and update C# scripts within Unity.
- **Editor Automation**: Automate Unity Editor tasks like building projects or entering play mode.

## Contributing

We welcome contributions to make the Unity MCP Server even better! Here's how to contribute:

1. **Fork the Repository**  
   Fork [github.com/justinpbarnett/unity-mcp](https://github.com/justinpbarnett/unity-mcp) | <details><summary>ai, a...</summary><p>ai, ai-integration, mcp, unity</p></details> | 717 | https://github.com/justinpbarnett/unity-mcp |
| **[Skywork-R1V](https://github.com/SkyworkAI/Skywork-R1V)** | Pioneering Multimodal Reasoning with CoT | Python | # Skywork-R1V: Pioneering Multimodal Reasoning with CoT
<font size=7><div align='center' > [[ğŸ“–Technical Report](https://github.com/SkyworkAI/Skywork-R1V/blob/main/Skywork_R1V.pdf)] [[ğŸ¤— Skywork-R1V-38B](https://huggingface.co/Skywork/Skywork-R1V-38B)] </div></font>

Welcome to the Skywork-R1V repository! Here, you'll find the model weights and inference code for our state-of-the-art open-sourced multimodal reasoning model, enabling advanced visual and logical thinking.

## ğŸ”¥News
**Mar 18, 2025**: We are thrilled to introduce Skywork R1V, the first industry open-sourced multimodal reasoning model with advanced visual chain-of-thought capabilities, pushing the boundaries of AI-driven vision and logical inference! ğŸš€

<div align="center">
  <table>
    <tr>
      <td>
        <img src="https://github.com/SkyworkAI/Skywork-R1V/blob/main/imgs/math_r1v.gif" width="450" height="400" alt="math_r1v" />
      </td>
      <td>
        <img src="https://github.com/SkyworkAI/Skywork-R1V/blob/main/imgs/Chemistry_cn.gif" width="450" height="400" alt="chemistry_1" />
      </td>
    </tr>
  </table>
</div>

## Features
- **Visual Chain-of-Thought**: Enables multi-step logical reasoning on visual inputs, breaking down complex image-based problems into manageable steps.
- **Mathematical & Scientific Analysis**: Capable of solving visual math problems and interpreting scientific/medical imagery with high precision.
- **Cross-Modal Understanding**: Seamlessly integrates text and images for richer, context-aware comprehension.

## Evaluation 
<div align="center">
  <b>Evaluation results of state-of-the-art LLMs and VLMs</b>
</div>
<table>
  <thead>
    <tr>
      <th></th>
      <th align="center"><strong>Size</strong></th>
      <th align="center"><strong>Vision</strong></th>
      <th align="center" colspan="3"><strong>Reasoning</strong></th>
      <th align="center" colspan="3"><strong>Vision</strong></th>
    </tr>
    <tr>
      <th></th>
      <th align="center"></th>
      <th></th>
      <th align="center"><strong>MATH-500</strong></th>
      <th align="center"><strong>AIME 2024</strong></th>
      <th align="center"><strong>GPQA</strong></th>
      <th align="center"><strong>MathVista(mini)</strong></th>
      <th align="center"><strong>MMMU(Val)</strong></th>
    </tr>
    <tr>
      <th></th>
      <th align="center"></th>
      <th></th>
      <th align="center">pass@1</th>
      <th align="center">pass@1</th>
      <th align="center">pass@1</th>
      <th align="center">pass@1</th>
      <th align="center">pass@1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Qwen2.5-72B-Instruct</td>
      <td align="center">72B</td>
      <td align="center">âŒ</td>
      <td align="center">80.0</td>
      <td align="center">23.3</td>
      <td align="center">49.0</td>
      <td align="center">-</td>
      <td align="center">-</td>
    </tr>
    <tr>
      <td>Deepseek V3</td>
      <td align="center">671B</td>
      <td align="center">âŒ</td>
      <td align="center">90.2</td>
      <td align="center">39.2</td>
      <td align="center">59.1</td>
      <td align="center">-</td>
      <td align="center">-</td>
    </tr>
    <tr>
      <td>Deepseek R1</td>
      <td align="center">671B</td>
      <td align="center">âŒ</td>
      <td align="center">97.3</td>
      <td align="center">79.8</td>
 | <details><summary>deeps...</summary><p>deepseek-r1, llm, mllm</p></details> | 663 | https://github.com/SkyworkAI/Skywork-R1V |
| **[open-wegram-bot](https://github.com/wozulong/open-wegram-bot)** | ã€é›¶è´¹ç”¨ã€‘ä¸€ä¸ªè®©äººå‘¼å¸é¡ºç•…çš„ Telegram åŒå‘ç§èŠæœºå™¨äºº ğŸ¤– / [Zero Cost] A Smooth-Operating Two-Way Private Messaging Telegram Bot ğŸ¤–  | JavaScript | # Open Wegram Bot - OWB
## ä¸€ä¸ªè®©äººå‘¼å¸é¡ºç•…çš„ Telegram åŒå‘ç§èŠæœºå™¨äºº ğŸ¤–ï¼ˆé›¶è´¹ç”¨ï¼‰
### *LivegramBot ä¸æ­»ï¼Œæˆ˜æ–—ä¸æ­¢ï¼*

ç®€ä½“ä¸­æ–‡ | [English](README_EN.md) 

è¿™æ˜¯ä¸€ä¸ªåŸºäº Cloudflare Worker / Vercel çš„ Telegram åŒå‘ç§èŠæœºå™¨äººï¼Œæ— éœ€æœåŠ¡å™¨ã€æ— éœ€æ•°æ®åº“ã€æ— éœ€è‡ªå·±çš„åŸŸåå³å¯è½»æ¾éƒ¨ç½²ã€‚

ç”¨æˆ·å¯ä»¥é€šè¿‡æ‚¨çš„æœºå™¨äººå‘æ‚¨å‘é€æ¶ˆæ¯ï¼Œæ‚¨å¯ä»¥ç›´æ¥å›å¤è¿™äº›æ¶ˆæ¯ï¼Œå®ç°åŒå‘é€šä¿¡ã€‚

## âœ¨ ç‰¹è‰²åŠŸèƒ½

- ğŸ”„ **åŒå‘é€šä¿¡** - è½»æ¾æ¥æ”¶å’Œå›å¤æ¥è‡ªç”¨æˆ·çš„æ¶ˆæ¯
- ğŸ’¾ **æ— éœ€æ•°æ®åº“** - å®Œå…¨æ— çŠ¶æ€è®¾è®¡ï¼Œé›¶å­˜å‚¨æˆæœ¬
- ğŸŒ **æ— éœ€è‡ªå·±çš„åŸŸå** - ä½¿ç”¨ Cloudflare Worker æä¾›çš„å…è´¹åŸŸå
- ğŸš€ **è½»é‡çº§éƒ¨ç½²** - å‡ åˆ†é’Ÿå†…å³å¯å®Œæˆè®¾ç½®
- ğŸ’° **é›¶æˆæœ¬è¿è¡Œ** - åœ¨ Cloudflare å…è´¹è®¡åˆ’èŒƒå›´å†…ä½¿ç”¨
- ğŸ”’ **å®‰å…¨å¯é ** - ä½¿ç”¨ Telegram å®˜æ–¹ API å’Œå®‰å…¨ä»¤ç‰Œ
- ğŸ”Œ **å¤šæœºå™¨äººæ”¯æŒ** - ä¸€ä¸ªéƒ¨ç½²å¯æ³¨å†Œå¤šä¸ªç§èŠæœºå™¨äºº
- ğŸ› ï¸ **å¤šç§éƒ¨ç½²æ–¹å¼** - æ”¯æŒ GitHub ä¸€é”®éƒ¨ç½²ã€Vercel ä¸€é”®éƒ¨ç½²ã€Wrangler CLI å’Œ Dashboard éƒ¨ç½²

## ğŸ› ï¸ å‰ç½®è¦æ±‚

- Cloudflare è´¦å·
- Telegram è´¦å·
- ä¸€ä¸ªç§‘å­¦å·¥å…·ï¼ˆä»…è®¾ç½®é˜¶æ®µéœ€è¦ï¼Œç”¨äºè®¿é—® Worker é»˜è®¤åŸŸåï¼Œè‡ªç»‘åŸŸåæ— è§†ï¼‰

## ğŸ“ è®¾ç½®æ­¥éª¤

### 1. è·å– Telegram UID

> [!NOTE]
> æ‚¨éœ€è¦çŸ¥é“è‡ªå·±çš„ Telegram ç”¨æˆ· ID (UID)ï¼Œè¿™æ˜¯ä¸€ä¸²æ•°å­—ï¼Œç”¨äºå°†æ¶ˆæ¯è½¬å‘ç»™æ‚¨ã€‚

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–ï¼š

- å‘ [@userinfobot](https://t.me/userinfobot) å‘é€ä»»æ„æ¶ˆæ¯ï¼Œå®ƒä¼šå‘Šè¯‰æ‚¨è‡ªå·±çš„ UID

è¯·è®°ä¸‹æ‚¨çš„æ•°å­— IDï¼ˆä¾‹å¦‚ï¼š`123456789`ï¼‰ã€‚

### 2. åˆ›å»º Telegram Bot

1. åœ¨ Telegram ä¸­æœç´¢å¹¶æ‰“å¼€ [@BotFather](https://t.me/BotFather)
2. å‘é€ `/newbot` å‘½ä»¤
3. æŒ‰ç…§æç¤ºè®¾ç½®æ‚¨çš„æœºå™¨äººåç§°å’Œç”¨æˆ·åï¼ˆç”¨æˆ·åå¿…é¡»ä»¥ `bot` ç»“å°¾ï¼‰
4. æˆåŠŸåï¼ŒBotFather ä¼šå‘ç»™æ‚¨ä¸€ä¸ª Bot API Tokenï¼ˆæ ¼å¼ç±»ä¼¼ï¼š`000000000:ABCDEFGhijklmnopqrstuvwxyz`ï¼‰
5. è¯·å®‰å…¨ä¿å­˜è¿™ä¸ª Bot API Token

### 3. é€‰æ‹©éƒ¨ç½²æ–¹å¼

#### æ–¹æ³•ä¸€ï¼šGitHub ä¸€é”®éƒ¨ç½²ï¼ˆæ¨è â­ï¼‰

è¿™æ˜¯æœ€ç®€å•çš„éƒ¨ç½²æ–¹å¼ï¼Œæ— éœ€æœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œç›´æ¥é€šè¿‡ GitHub ä»“åº“éƒ¨ç½²ã€‚

1. Fork æˆ–å…‹éš†æœ¬ä»“åº“åˆ°æ‚¨çš„ GitHub è´¦æˆ·
2. ç™»å½• [Cloudflare Dashboard](https://dash.cloudflare.com/)
3. å¯¼èˆªåˆ° **Workers & Pages** éƒ¨åˆ†
4. ç‚¹å‡» **Create Application**
5. é€‰æ‹© **Connect to Git**
6. æˆæƒ Cloudflare è®¿é—®æ‚¨çš„ GitHubï¼Œå¹¶é€‰æ‹©æ‚¨ fork çš„ä»“åº“
7. é…ç½®éƒ¨ç½²è®¾ç½®ï¼š
   - **Project name**ï¼šè®¾ç½®æ‚¨çš„é¡¹ç›®åç§°ï¼ˆä¾‹å¦‚ `open-wegram-bot`ï¼‰
   - **Production branch**ï¼šé€‰æ‹©ä¸»åˆ†æ”¯ï¼ˆé€šå¸¸æ˜¯ `master`ï¼‰
   - å…¶ä»–è®¾ç½®ä¿æŒé»˜è®¤
8. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   - ç‚¹å‡» **Environment Variables**
   - æ·»åŠ  `PREFIX`ï¼ˆä¾‹å¦‚ï¼š`public`ï¼‰
   - æ·»åŠ  `SECRET_TOKEN`ï¼ˆå¿…é¡»åŒ…å«å¤§å°å†™å­—æ¯å’Œæ•°å­—ï¼Œé•¿åº¦è‡³å°‘16ä½ï¼‰ï¼Œå¹¶æ ‡è®°ä¸º**åŠ å¯†**
9. ç‚¹å‡» **Save and Deploy** æŒ‰é’®å®Œæˆéƒ¨ç½²

è¿™ç§æ–¹å¼çš„ä¼˜ç‚¹æ˜¯ï¼šå½“æ‚¨æ›´æ–° GitHub ä»“åº“æ—¶ï¼ŒCloudflare ä¼šè‡ªåŠ¨é‡æ–°éƒ¨ç½²æ‚¨çš„ Workerã€‚

#### æ–¹æ³•äºŒï¼šVercel ä¸€é”®éƒ¨ç½²

Vercel æä¾›äº†å¦ä¸€ç§ç®€å•çš„éƒ¨ç½²æ–¹å¼ï¼Œä¹Ÿæ”¯æŒä» GitHub ä»“åº“è‡ªåŠ¨éƒ¨ç½²ã€‚

1. ç‚¹å‡»ä¸‹æ–¹çš„"Deploy with Vercel"æŒ‰é’®ï¼š

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fwozulong%2Fopen-wegram-bot&env=SECRET_TOKEN,PREFIX&envDescription=é…ç½®æ‚¨çš„æœºå™¨äººå‚æ•°&project-name=open-wegram-bot&repository-name=open-wegram-bot)

2. æŒ‰ç…§ Vercel çš„æç¤ºå®Œæˆéƒ¨ç½²æµç¨‹
3. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   - `PREFIX`ï¼šè®¾ç½®ä¸ºæ‚¨æƒ³è¦çš„ URL å‰ç¼€ï¼ˆä¾‹å¦‚ `public`ï¼‰
   - `SECRET_TOKEN`ï¼šè®¾ç½®ä¸€ä¸ªå®‰å…¨çš„ä»¤ç‰Œï¼ˆå¿…é¡»åŒ…å«å¤§å°å†™å­—æ¯å’Œæ•°å­—ï¼Œé•¿åº¦è‡³å°‘16ä½ï¼‰
4. å®Œæˆéƒ¨ç½²åï¼ŒVercel ä¼šæä¾›ä¸€ä¸ªåŸŸåï¼Œå¦‚ ` | <details><summary>teleg...</summary><p>telegram, telegram-bot, telegram-bots</p></details> | 646 | https://github.com/wozulong/open-wegram-bot |
| **[Classless.css](https://github.com/DigitallyTailored/Classless.css)** | A lightweight, classless CSS framework that makes simple websites look better without requiring any additional markup. | CSS | # Classless.css

A lightweight CSS framework for websites with impeccable taste but zero desire to add classes.

## Preview

Check out the live demo: [Classless.css Demo](https://digitallytailored.github.io/Classless.css/)

## How to Use

To use Classless.css in your project, simply add the following line to the `<head>` section of your HTML:

```html
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/digitallytailored/classless@latest/classless.min.css">
```

This link always points to the latest version of the minified CSS.

## Features

- **No classes required**: Enjoy a clean and simple markup without the need for CSS classes.
- **Responsive design**: Automatically adapts to different screen sizes for a seamless experience.
- **Dark mode support**: Easily switch between light and dark themes.
- **Typography enhancements**: Improved font styles for better readability.
- **Form styling**: Styled forms that look great out of the box.
- **Table improvements**: Enhanced table styles for a more polished appearance.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is open source and available under the [MIT License](https://opensource.org/license/mit). |  | 589 | https://github.com/DigitallyTailored/Classless.css |
| **[DAPO](https://github.com/BytedTsinghua-SIA/DAPO)** | An Open-source RL System from ByteDance Seed and Tsinghua AIR |  | # DAPO: an Open-source RL System from ByteDance Seed and Tsinghua AIR

<div align='center'>
[![Paper](https://img.shields.io/badge/paper-5f16a8?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/pdf/2503.14476)
[![Blog](https://img.shields.io/badge/Blog-3858bf?style=for-the-badge&logo=homepage&logoColor=white)](https://DAPO-SIA.github.io/)
[![Dataset](https://img.shields.io/badge/Datasets-4d8cd8?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k)
[![Weights](https://img.shields.io/badge/Model%20Weights(coming%20soon)-63cad3?style=for-the-badge&logo=huggingface&logoColor=white)](https://github.com/BytedTsinghua-SIA/DAPO)
</div>

We are excited to announce the release of **DAPO**, a fully open-sourced system for large-scale reinforcement learning (RL) with large language models (LLMs). DAPO stands for **D**ecoupled Clip and **D**ynamic s**A**mpling **P**olicy **O**ptimization, which is a novel algorithm designed to achieve state-of-the-art performance in LLM RL tasks.

Through this initiative, we aim to provide the research community and society with practical access to scalable reinforcement learning, fostering innovation and collaboration in this exciting field. Our system builds upon the impressive [verl](https://github.com/volcengine/verl) framework, and we extend our gratitude to the developers for their outstanding work.

## Discussions Welcomed

If you have any questions or comments regarding our paper or the DAPO system, please feel free to open issues on our GitHub repository. We welcome discussions and feedback!

## Key Results

### AIME 2024 Performance

ğŸš€ **DAPO** achieves an impressive score of **50 points** on the AIME 2024 benchmark using the Qwen2.5-32B base model, surpassing the previous state-of-the-art (SoTA) model, DeepSeek-R1-Zero-Qwen-32B, while utilizing 50% fewer training steps.

![Performance Score](img/score.png)

### Metric Supervision during Training

1. **Length Stability and Growth**: The gradual increase in response length promotes exploration, enabling the model to learn complex reasoning behaviors, thus enhancing training stability and performance.
  
2. **Reward Score Stability**: A consistent rise in reward signals indicates that the model is effectively fitting the training distribution, ensuring a robust and stable learning process.

3. **Entropy and Mean Probability Trend**: A controlled increase in entropy, following an initial decrease, maintains a balance between exploration and exploitation, preventing overfitting and promoting sustained model performance.

![Training Metrics](img/dynamic.png)

## Reproducibility

To support the research community, we are providing comprehensive resources for reproducing our RL training process, including algorithm details, datasets, and infrastructure.

### Datasets

We offer both training and validation datasets for DAPO:

- **Training**: [DAPO-Math-17k](https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k) - A carefully curated math dataset.
- **Validation**: [AIME 2024](https://huggingface.co/datasets/BytedTsinghua-SIA/AIME-2024).

### Training

We provide an [out-of-the-box](https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo) script for reproducing DAPO training. The core code and quickstart instructions can be found in the [README](https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo/README.md). The scripts include:

- [Datasets Preparation](https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo/prepare_dapo_data.sh)
- [DAPO w/o Dynamic Sampling -- AIME 44](https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo/run_dapo_early_qwen2.5_32b.sh)
- [DAPO Full -- AIME 50](https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo/run_dapo_qwen2.5_32b.sh)

**Note**:
 |  | 586 | https://github.com/BytedTsinghua-SIA/DAPO |
| **[rag-zero-to-hero-guide](https://github.com/KalyanKS-NLP/rag-zero-to-hero-guide)** | Comprehensive guide to learn RAG from basics to advanced.  | Jupyter Notebook | Request error occurred:  | <details><summary>ai-en...</summary><p>ai-engineer, generative-ai, large-language-models, llm-engineer, llm-rag, llms, retrieval-augmented-generation</p></details> | 425 | https://github.com/KalyanKS-NLP/rag-zero-to-hero-guide |

